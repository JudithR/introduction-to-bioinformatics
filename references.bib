---
---

@inproceedings{holdgraf_evidence_2014,
	address = {Brisbane, Australia, Australia},
	title = {Evidence for {Predictive} {Coding} in {Human} {Auditory} {Cortex}},
	booktitle = {International {Conference} on {Cognitive} {Neuroscience}},
	publisher = {Frontiers in Neuroscience},
	author = {Holdgraf, Christopher Ramsay and de Heer, Wendy and Pasley, Brian N. and Knight, Robert T.},
	year = {2014}
}

@article{holdgraf_rapid_2016,
	title = {Rapid tuning shifts in human auditory cortex enhance speech intelligibility},
	volume = {7},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms13654},
	doi = {10.1038/ncomms13654},
	number = {May},
	journal = {Nature Communications},
	author = {Holdgraf, Christopher Ramsay and de Heer, Wendy and Pasley, Brian N. and Rieger, Jochem W. and Crone, Nathan and Lin, Jack J. and Knight, Robert T. and Theunissen, Frédéric E.},
	year = {2016},
	pages = {13654},
	file = {Holdgraf et al. - 2016 - Rapid tuning shifts in human auditory cortex enhance speech intelligibility.pdf:C\:\\Users\\chold\\Zotero\\storage\\MDQP3JWE\\Holdgraf et al. - 2016 - Rapid tuning shifts in human auditory cortex enhance speech intelligibility.pdf:application/pdf}
}

@inproceedings{holdgraf_portable_2017,
	title = {Portable learning environments for hands-on computational instruction using container-and cloud-based technology to teach data science},
	volume = {Part F1287},
	isbn = {978-1-4503-5272-7},
	doi = {10.1145/3093338.3093370},
	abstract = {© 2017 ACM. There is an increasing interest in learning outside of the traditional classroom setting. This is especially true for topics covering computational tools and data science, as both are challenging to incorporate in the standard curriculum. These atypical learning environments offer new opportunities for teaching, particularly when it comes to combining conceptual knowledge with hands-on experience/expertise with methods and skills. Advances in cloud computing and containerized environments provide an attractive opportunity to improve the effciency and ease with which students can learn. This manuscript details recent advances towards using commonly-Available cloud computing services and advanced cyberinfrastructure support for improving the learning experience in bootcamp-style events. We cover the benets (and challenges) of using a server hosted remotely instead of relying on student laptops, discuss the technology that was used in order to make this possible, and give suggestions for how others could implement and improve upon this model for pedagogy and reproducibility.},
	booktitle = {{ACM} {International} {Conference} {Proceeding} {Series}},
	author = {Holdgraf, Christopher Ramsay and Culich, A. and Rokem, A. and Deniz, F. and Alegro, M. and Ushizima, D.},
	year = {2017},
	keywords = {Teaching, Bootcamps, Cloud computing, Data science, Docker, Pedagogy}
}

@article{holdgraf_encoding_2017,
	title = {Encoding and decoding models in cognitive electrophysiology},
	volume = {11},
	issn = {16625137},
	doi = {10.3389/fnsys.2017.00061},
	abstract = {© 2017 Holdgraf, Rieger, Micheli, Martin, Knight and Theunissen. Cognitive neuroscience has seen rapid growth in the size and complexity of data recorded from the human brain as well as in the computational tools available to analyze this data. This data explosion has resulted in an increased use of multivariate, model-based methods for asking neuroscience questions, allowing scientists to investigate multiple hypotheses with a single dataset, to use complex, time-varying stimuli, and to study the human brain under more naturalistic conditions. These tools come in the form of “Encoding” models, in which stimulus features are used to model brain activity, and “Decoding” models, in which neural features are used to generated a stimulus output. Here we review the current state of encoding and decoding models in cognitive electrophysiology and provide a practical guide toward conducting experiments and analyses in this emerging field. Our examples focus on using linear models in the study of human language and audition. We show how to calculate auditory receptive fields from natural sounds as well as how to decode neural recordings to predict speech. The paper aims to be a useful tutorial to these approaches, and a practical introduction to using machine learning and applied statistics to build models of neural activity. The data analytic approaches we discuss may also be applied to other sensory modalities, motor systems, and cognitive systems, and we cover some examples in these areas. In addition, a collection of Jupyter notebooks is publicly available as a complement to the material covered in this paper, providing code examples and tutorials for predictive modeling in python. The aimis to provide a practical understanding of predictivemodeling of human brain data and to propose best-practices in conducting these analyses.},
	journal = {Frontiers in Systems Neuroscience},
	author = {Holdgraf, Christopher Ramsay and Rieger, J.W. and Micheli, C. and Martin, S. and Knight, R.T. and Theunissen, F.E.},
	year = {2017},
	keywords = {Decoding models, Encoding models, Electrocorticography (ECoG), Electrophysiology/evoked potentials, Machine learning applied to neuroscience, Natural stimuli, Predictive modeling, Tutorials}
}

@book{ruby,
  title     = {The Ruby Programming Language},
  author    = {Flanagan, David and Matsumoto, Yukihiro},
  year      = {2008},
  publisher = {O'Reilly Media}
}

@article{t2t_human_genome,
	author = {Sergey Nurk  and Sergey Koren  and Arang Rhie  and Mikko Rautiainen  and Andrey V. Bzikadze  and Alla Mikheenko  and Mitchell R. Vollger  and Nicolas Altemose  and Lev Uralsky  and Ariel Gershman  and Sergey Aganezov  and Savannah J. Hoyt  and Mark Diekhans  and Glennis A. Logsdon  and Michael Alonge  and Stylianos E. Antonarakis  and Matthew Borchers  and Gerard G. Bouffard  and Shelise Y. Brooks  and Gina V. Caldas  and Nae-Chyun Chen  and Haoyu Cheng  and Chen-Shan Chin  and William Chow  and Leonardo G. de Lima  and Philip C. Dishuck  and Richard Durbin  and Tatiana Dvorkina  and Ian T. Fiddes  and Giulio Formenti  and Robert S. Fulton  and Arkarachai Fungtammasan  and Erik Garrison  and Patrick G. S. Grady  and Tina A. Graves-Lindsay  and Ira M. Hall  and Nancy F. Hansen  and Gabrielle A. Hartley  and Marina Haukness  and Kerstin Howe  and Michael W. Hunkapiller  and Chirag Jain  and Miten Jain  and Erich D. Jarvis  and Peter Kerpedjiev  and Melanie Kirsche  and Mikhail Kolmogorov  and Jonas Korlach  and Milinn Kremitzki  and Heng Li  and Valerie V. Maduro  and Tobias Marschall  and Ann M. McCartney  and Jennifer McDaniel  and Danny E. Miller  and James C. Mullikin  and Eugene W. Myers  and Nathan D. Olson  and Benedict Paten  and Paul Peluso  and Pavel A. Pevzner  and David Porubsky  and Tamara Potapova  and Evgeny I. Rogaev  and Jeffrey A. Rosenfeld  and Steven L. Salzberg  and Valerie A. Schneider  and Fritz J. Sedlazeck  and Kishwar Shafin  and Colin J. Shew  and Alaina Shumate  and Ying Sims  and Arian F. A. Smit  and Daniela C. Soto  and Ivan Sović  and Jessica M. Storer  and Aaron Streets  and Beth A. Sullivan  and Françoise Thibaud-Nissen  and James Torrance  and Justin Wagner  and Brian P. Walenz  and Aaron Wenger  and Jonathan M. D. Wood  and Chunlin Xiao  and Stephanie M. Yan  and Alice C. Young  and Samantha Zarate  and Urvashi Surti  and Rajiv C. McCoy  and Megan Y. Dennis  and Ivan A. Alexandrov  and Jennifer L. Gerton  and Rachel J. O’Neill  and Winston Timp  and Justin M. Zook  and Michael C. Schatz  and Evan E. Eichler  and Karen H. Miga  and Adam M. Phillippy },
	title = {The complete sequence of a human genome},
	journal = {Science},
	volume = {376},
	number = {6588},
	pages = {44-53},
	year = {2022},
	doi = {10.1126/science.abj6987},
	URL = {https://www.science.org/doi/abs/10.1126/science.abj6987},
	eprint = {https://www.science.org/doi/pdf/10.1126/science.abj6987},
	abstract = {Since its initial release in 2000, the human reference genome has covered only the euchromatic fraction of the genome, leaving important heterochromatic regions unfinished. Addressing the remaining 8\% of the genome, the Telomere-to-Telomere (T2T) Consortium presents a complete 3.055 billion–base pair sequence of a human genome, T2T-CHM13, that includes gapless assemblies for all chromosomes except Y, corrects errors in the prior references, and introduces nearly 200 million base pairs of sequence containing 1956 gene predictions, 99 of which are predicted to be protein coding. The completed regions include all centromeric satellite arrays, recent segmental duplications, and the short arms of all five acrocentric chromosomes, unlocking these complex regions of the genome to variational and functional studies.}
}
